2020-01-28T14:26:41.452+1100 I CONTROL  [initandlisten] MongoDB starting : pid=38111 port=27020 dbpath=/Users/gc/Documents/test_environment/3.7.9/data/shard01/rs3/db 64-bit host=gc.local
2020-01-28T14:26:41.453+1100 I CONTROL  [initandlisten] db version v3.7.9
2020-01-28T14:26:41.453+1100 I CONTROL  [initandlisten] git version: 681d1e0bf8d45c366848678811bad6f1a471f20c
2020-01-28T14:26:41.454+1100 I CONTROL  [initandlisten] allocator: system
2020-01-28T14:26:41.454+1100 I CONTROL  [initandlisten] modules: none
2020-01-28T14:26:41.455+1100 I CONTROL  [initandlisten] build environment:
2020-01-28T14:26:41.456+1100 I CONTROL  [initandlisten]     distarch: x86_64
2020-01-28T14:26:41.456+1100 I CONTROL  [initandlisten]     target_arch: x86_64
2020-01-28T14:26:41.457+1100 I CONTROL  [initandlisten] options: { net: { port: 27020 }, processManagement: { fork: true }, replication: { replSet: "shard01" }, sharding: { clusterRole: "shardsvr" }, storage: { dbPath: "/Users/gc/Documents/test_environment/3.7.9/data/shard01/rs3/db", wiredTiger: { engineConfig: { cacheSizeGB: 1.0 } } }, systemLog: { destination: "file", path: "/Users/gc/Documents/test_environment/3.7.9/data/shard01/rs3/mongod.log" } }
2020-01-28T14:26:41.458+1100 I STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=1024M,session_max=20000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000),statistics_log=(wait=0),verbose=(recovery_progress),
2020-01-28T14:26:41.886+1100 I STORAGE  [initandlisten] WiredTiger message [1580182001:886675][38111:0x1210885c0], txn-recover: Set global recovery timestamp: 0
2020-01-28T14:26:41.916+1100 I RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2020-01-28T14:26:41.961+1100 I CONTROL  [initandlisten] 
2020-01-28T14:26:41.963+1100 I CONTROL  [initandlisten] ** NOTE: This is a development version (3.7.9) of MongoDB.
2020-01-28T14:26:41.964+1100 I CONTROL  [initandlisten] **       Not recommended for production.
2020-01-28T14:26:41.965+1100 I CONTROL  [initandlisten] 
2020-01-28T14:26:41.967+1100 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2020-01-28T14:26:41.968+1100 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2020-01-28T14:26:41.969+1100 I CONTROL  [initandlisten] 
2020-01-28T14:26:41.970+1100 I CONTROL  [initandlisten] ** WARNING: This server is bound to localhost.
2020-01-28T14:26:41.971+1100 I CONTROL  [initandlisten] **          Remote systems will be unable to connect to this server. 
2020-01-28T14:26:41.971+1100 I CONTROL  [initandlisten] **          Start the server with --bind_ip <address> to specify which IP 
2020-01-28T14:26:41.972+1100 I CONTROL  [initandlisten] **          addresses it should serve responses from, or with --bind_ip_all to
2020-01-28T14:26:41.973+1100 I CONTROL  [initandlisten] **          bind to all interfaces. If this behavior is desired, start the
2020-01-28T14:26:41.974+1100 I CONTROL  [initandlisten] **          server with --bind_ip 127.0.0.1 to disable this warning.
2020-01-28T14:26:41.974+1100 I CONTROL  [initandlisten] 
2020-01-28T14:26:41.975+1100 I CONTROL  [initandlisten] 
2020-01-28T14:26:41.976+1100 I CONTROL  [initandlisten] ** WARNING: soft rlimits too low. Number of files is 256, should be at least 1000
2020-01-28T14:26:41.979+1100 W SHARDING [initandlisten] Started with --shardsvr, but no shardIdentity document was found on disk in admin.system.version. This most likely means this server has not yet been added to a sharded cluster.
2020-01-28T14:26:41.981+1100 I STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 2f69b51e-ee60-4311-8acd-ca0f620478ee
2020-01-28T14:26:42.016+1100 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/Users/gc/Documents/test_environment/3.7.9/data/shard01/rs3/db/diagnostic.data'
2020-01-28T14:26:42.019+1100 I STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: ef529829-4a1b-4e36-ba3b-5513868df99c
2020-01-28T14:26:42.062+1100 I STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: 0514ee09-f4d0-4c00-b8ff-a6954607b429
2020-01-28T14:26:42.102+1100 I REPL     [initandlisten] Did not find local voted for document at startup.
2020-01-28T14:26:42.104+1100 I REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2020-01-28T14:26:42.105+1100 I STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 2eb6f3c5-7527-4cf7-9f2b-2509f9c653fa
2020-01-28T14:26:42.144+1100 I REPL     [initandlisten] Initialized the rollback ID to 1
2020-01-28T14:26:42.146+1100 I REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2020-01-28T14:26:42.147+1100 I NETWORK  [initandlisten] waiting for connections on port 27020
2020-01-28T14:26:54.252+1100 I REPL     [replexec-0] New replica set config in use: { _id: "shard01", version: 1, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "localhost:27018", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "localhost:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "localhost:27020", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5e2fa9fcc4e02a320b990cfc') } }
2020-01-28T14:27:05.515+1100 I NETWORK  [repl writer worker 5] Starting new replica set monitor for configRepl/localhost:27033
2020-01-28T14:27:05.551+1100 I NETWORK  [shard registry reload] Starting new replica set monitor for shard01/localhost:27018,localhost:27019,localhost:27020
2020-01-28T14:27:35.565+1100 I NETWORK  [shard registry reload] Starting new replica set monitor for shard02/localhost:27021,localhost:27022,localhost:27023
2020-01-28T14:27:35.567+1100 I NETWORK  [shard registry reload] Starting new replica set monitor for shard03/localhost:27024,localhost:27025,localhost:27026
2020-01-28T14:27:35.567+1100 I NETWORK  [shard registry reload] Starting new replica set monitor for shard04/localhost:27027,localhost:27028,localhost:27029
2020-01-28T14:27:35.568+1100 I NETWORK  [shard registry reload] Starting new replica set monitor for shard05/localhost:27030,localhost:27031,localhost:27032
2020-01-28T14:34:38.592+1100 I SHARDING [migrateThread] about to log metadata event into changelog: { _id: "gc.local-2020-01-28T14:34:38.591+1100-5e2fabce2bbdbea998b6f719", server: "gc.local", clientAddr: "", time: new Date(1580182478591), what: "moveChunk.to", ns: "test.products", details: { min: { sku: 23153496 }, max: { sku: 28928914 }, step 1 of 6: 202, step 2 of 6: 219, step 3 of 6: 14698, step 4 of 6: 0, step 5 of 6: 59, step 6 of 6: 252, note: "success" } }
2020-01-28T14:53:31.076+1100 I SHARDING [migrateThread] about to log metadata event into changelog: { _id: "gc.local-2020-01-28T14:53:31.076+1100-5e2fb03b2bbdbea998b70eed", server: "gc.local", clientAddr: "", time: new Date(1580183611076), what: "moveChunk.to", ns: "test.products", details: { min: { sku: 28928914 }, max: { sku: 30509163 }, step 1 of 6: 169, step 2 of 6: 188, step 3 of 6: 2062, step 4 of 6: 0, step 5 of 6: 52, step 6 of 6: 204, note: "success" } }
2020-01-28T15:59:39.650+1100 I SHARDING [conn80] Deletion of test.products range [{ sku: 9999265900050000 }, { sku: MaxKey }) will be scheduled after all possibly dependent queries finish
2020-01-28T15:59:39.652+1100 I SHARDING [conn80] about to log metadata event into changelog: { _id: "gc.local-2020-01-28T15:59:39.652+1100-5e2fbfbb42d5e3b340857469", server: "gc.local", clientAddr: "127.0.0.1:59531", time: new Date(1580187579652), what: "moveChunk.from", ns: "test.products", details: { min: { sku: 9999265900050000 }, max: { sku: MaxKey }, step 1 of 6: 0, step 2 of 6: 47, step 3 of 6: 102, step 4 of 6: 85, step 5 of 6: 423, step 6 of 6: 118, to: "shard02", from: "shard01", note: "success" } }
2020-01-28T16:01:59.466+1100 I SHARDING [conn80] about to log metadata event into changelog: { _id: "gc.local-2020-01-28T16:01:59.466+1100-5e2fc04742d5e3b3408a48ae", server: "gc.local", clientAddr: "127.0.0.1:59531", time: new Date(1580187719466), what: "moveChunk.from", ns: "test.products", details: { min: { sku: 30509163 }, max: { sku: 280124000.0 }, step 1 of 6: 0, step 2 of 6: 47, step 3 of 6: 319, step 4 of 6: 24849, step 5 of 6: 401, step 6 of 6: 142, to: "shard05", from: "shard01", note: "success" } }
2020-01-28T16:02:27.344+1100 I SHARDING [conn80] about to log metadata event into changelog: { _id: "gc.local-2020-01-28T16:02:27.343+1100-5e2fc06342d5e3b3408ae017", server: "gc.local", clientAddr: "127.0.0.1:59531", time: new Date(1580187747343), what: "moveChunk.from", ns: "test.products", details: { min: { sku: 280124000.0 }, max: { sku: 702192000.0 }, step 1 of 6: 0, step 2 of 6: 27, step 3 of 6: 445, step 4 of 6: 25618, step 5 of 6: 456, step 6 of 6: 99, to: "shard03", from: "shard01", note: "success" } }
2020-01-28T16:04:43.964+1100 I SHARDING [conn80] about to log metadata event into changelog: { _id: "gc.local-2020-01-28T16:04:43.964+1100-5e2fc0eb42d5e3b3408f95f4", server: "gc.local", clientAddr: "127.0.0.1:59531", time: new Date(1580187883964), what: "moveChunk.from", ns: "test.products", details: { min: { sku: 702192000.0 }, max: { sku: 1121620000.0 }, step 1 of 6: 0, step 2 of 6: 48, step 3 of 6: 288, step 4 of 6: 23827, step 5 of 6: 415, step 6 of 6: 90, to: "shard04", from: "shard01", note: "success" } }
2020-01-28T16:14:39.689+1100 I SHARDING [Collection Range Deleter] Deferring deletion of test.products range [{ sku: 30509163 }, { sku: 280124000.0 }) until 2020-01-28T16:16:59.464+1100
2020-01-28T16:18:30.800+1100 I SHARDING [Collection Range Deleter] Deferring deletion of test.products range [{ sku: 702192000.0 }, { sku: 1121620000.0 }) until 2020-01-28T16:19:43.953+1100
2020-01-29T15:20:30.800+1100 W SHARDING [ChunkSplitter-80] Finding the split vector for test.products over { sku: 1.0 } keyCount: 29641 numSplits: 1 lookedAt: 19983 took 111ms
2020-01-29T15:22:30.800+1100 I SHARDING [ChunkSplitter-79] autosplitted test.products chunk: shard: shard01, lastmod: 1106|31||5ddf12dbc2e6060a9c3bdd01, [{ sku: 28928914 }, { sku: 30509163 }) into 3 parts (maxChunkSizeBytes 67108864)
2020-01-29T15:25:30.800+1100 W SHARDING [ChunkSplitter-80] Finding the split vector for test.products over { sku: 1.0 } keyCount: 29641 numSplits: 1 lookedAt: 19961 took 127ms
2020-01-29T15:30:30.800+1100 W SHARDING [ChunkSplitter-80] Finding the split vector for test.products over { sku: 1.0 } keyCount: 29641 numSplits: 1 lookedAt: 20087 took 113ms
2020-01-29T15:45:30.800+1100 W SHARDING [ChunkSplitter-80] Finding the split vector for test.products over { sku: 1.0 } keyCount: 29641 numSplits: 1 lookedAt: 19849 took 303ms
2020-01-29T15:50:30.800+1100 W SHARDING [ChunkSplitter-82] Finding the split vector for test.products over { sku: 1.0 } keyCount: 29641 numSplits: 1 lookedAt: 20487 took 110ms
2020-01-29T16:22:30.800+1100 I SHARDING [ChunkSplitter-82] autosplitted test.products chunk: shard: shard01, lastmod: 1106|37||5ddf12dbc2e6060a9c3bdd01, [{ sku: 28928914 }, { sku: 30509163 }) into 3 parts (maxChunkSizeBytes 67108864)
2020-01-29T16:23:30.800+1100 I SHARDING [ChunkSplitter-82] autosplitted test.products chunk: shard: shard01, lastmod: 1106|16||5ddf12dbc2e6060a9c3bdd01, [{ sku: 23153496 }, { sku: 28928914 }) into 3 parts (maxChunkSizeBytes 67108864)
2020-01-29T16:34:30.800+1100 I SHARDING [ChunkSplitter-85] autosplitted test.products chunk: shard: shard01, lastmod: 1106|43||5ddf12dbc2e6060a9c3bdd01, [{ sku: 23153496 }, { sku: 28928914 }) into 3 parts (maxChunkSizeBytes 67108864)
